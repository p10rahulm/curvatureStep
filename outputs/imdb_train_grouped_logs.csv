Optimizer Name|Mean_Training_Loss_epoch1|Mean_Training_Loss_epoch2|Std_Training_Loss_epoch1|Std_Training_Loss_epoch2
AMSGrad|0.00953|0.00081|0.0011557104597028907|0.0007370361064576294
Adadelta|0.00396|2.9999999999999997e-05|0.000302581485810939|9.486832980505137e-05
Adagrad|0.013439999999999999|0.00097|0.015116304663067183|0.0014391741458983421
Adam|0.01014|0.00156|0.0019328735085359313|0.0029762765701833263
AdamW|0.01005|0.00040999999999999994|0.0014238055422782364|0.0004605552204797065
HeavyBall|0.093|0.00787|0.005280993172584954|0.0019373808207072873
HeavyBallCurvature|0.00583|2e-05|0.0002668749186833079|4.216370213557839e-05
NAG|0.093|0.00787|0.005280993172584954|0.0019373808207072873
NAGCurvature|0.00583|2e-05|0.0002668749186833079|4.216370213557839e-05
NAdam|0.01252|0.0083|0.012888823754624695|0.014685291205072434
NAdamW|0.01036|0.0052|0.006878016509947553|0.007020129786707809
RMSProp|0.02185|0.0023899999999999998|0.007183507345146781|0.004178370229859697
RMSPropMomentum|0.0252|0.0016899999999999999|0.010988276581075951|0.0031945961316642898
SimpleSGD|0.30935999999999997|0.14667|0.01815557459539324|0.010055076108889262
SimpleSGDCurvature|0.01046|0.0001|0.0004788875998951463|0.0
