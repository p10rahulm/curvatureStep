# ----------------------------------------------------------------------------------------------------
# Running 10 epochs of training - 10 runs
# ----------------------------------------------------------------------------------------------------

Running AG News Training with Optimizer = SimpleSGD
params= {'lr': 0.001}
Running Loop: 1/10
Epoch 1, Loss: 1.3836
Epoch 2, Loss: 1.3813
Epoch 3, Loss: 1.3795
Epoch 4, Loss: 1.3778
Epoch 5, Loss: 1.3761
Epoch 6, Loss: 1.3745
Epoch 7, Loss: 1.3728
Epoch 8, Loss: 1.3711
Epoch 9, Loss: 1.3693
Epoch 10, Loss: 1.3675
Test set: Average loss: 0.0214, Accuracy: 2376/7600 (31.26%)
accuracy= 0.3126315789473684
accuracies= [0.3126315789473684]
Running Loop: 2/10
Epoch 1, Loss: 1.3857
Epoch 2, Loss: 1.3835
Epoch 3, Loss: 1.3816
Epoch 4, Loss: 1.3797
Epoch 5, Loss: 1.3779
Epoch 6, Loss: 1.3761
Epoch 7, Loss: 1.3744
Epoch 8, Loss: 1.3726
Epoch 9, Loss: 1.3709
Epoch 10, Loss: 1.3692
Test set: Average loss: 0.0214, Accuracy: 2403/7600 (31.62%)
accuracy= 0.3161842105263158
accuracies= [0.3126315789473684, 0.3161842105263158]
Running Loop: 3/10
Epoch 1, Loss: 1.3852
Epoch 2, Loss: 1.3830
Epoch 3, Loss: 1.3810
Epoch 4, Loss: 1.3790
Epoch 5, Loss: 1.3770
Epoch 6, Loss: 1.3751
Epoch 7, Loss: 1.3731
Epoch 8, Loss: 1.3711
Epoch 9, Loss: 1.3691
Epoch 10, Loss: 1.3669
Test set: Average loss: 0.0214, Accuracy: 2438/7600 (32.08%)
accuracy= 0.3207894736842105
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105]
Running Loop: 4/10
Epoch 1, Loss: 1.3847
Epoch 2, Loss: 1.3823
Epoch 3, Loss: 1.3803
Epoch 4, Loss: 1.3785
Epoch 5, Loss: 1.3766
Epoch 6, Loss: 1.3747
Epoch 7, Loss: 1.3727
Epoch 8, Loss: 1.3706
Epoch 9, Loss: 1.3683
Epoch 10, Loss: 1.3659
Test set: Average loss: 0.0214, Accuracy: 2508/7600 (33.00%)
accuracy= 0.33
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33]
Running Loop: 5/10
Epoch 1, Loss: 1.3852
Epoch 2, Loss: 1.3831
Epoch 3, Loss: 1.3811
Epoch 4, Loss: 1.3791
Epoch 5, Loss: 1.3771
Epoch 6, Loss: 1.3751
Epoch 7, Loss: 1.3730
Epoch 8, Loss: 1.3709
Epoch 9, Loss: 1.3688
Epoch 10, Loss: 1.3664
Test set: Average loss: 0.0214, Accuracy: 2517/7600 (33.12%)
accuracy= 0.3311842105263158
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158]
Running Loop: 6/10
Epoch 1, Loss: 1.3864
Epoch 2, Loss: 1.3843
Epoch 3, Loss: 1.3823
Epoch 4, Loss: 1.3804
Epoch 5, Loss: 1.3786
Epoch 6, Loss: 1.3769
Epoch 7, Loss: 1.3751
Epoch 8, Loss: 1.3734
Epoch 9, Loss: 1.3717
Epoch 10, Loss: 1.3700
Test set: Average loss: 0.0214, Accuracy: 2357/7600 (31.01%)
accuracy= 0.3101315789473684
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158, 0.3101315789473684]
Running Loop: 7/10
Epoch 1, Loss: 1.3870
Epoch 2, Loss: 1.3845
Epoch 3, Loss: 1.3826
Epoch 4, Loss: 1.3807
Epoch 5, Loss: 1.3788
Epoch 6, Loss: 1.3769
Epoch 7, Loss: 1.3751
Epoch 8, Loss: 1.3733
Epoch 9, Loss: 1.3714
Epoch 10, Loss: 1.3695
Test set: Average loss: 0.0214, Accuracy: 2463/7600 (32.41%)
accuracy= 0.3240789473684211
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158, 0.3101315789473684, 0.3240789473684211]
Running Loop: 8/10
Epoch 1, Loss: 1.3866
Epoch 2, Loss: 1.3841
Epoch 3, Loss: 1.3822
Epoch 4, Loss: 1.3803
Epoch 5, Loss: 1.3785
Epoch 6, Loss: 1.3767
Epoch 7, Loss: 1.3750
Epoch 8, Loss: 1.3733
Epoch 9, Loss: 1.3715
Epoch 10, Loss: 1.3698
Test set: Average loss: 0.0215, Accuracy: 2382/7600 (31.34%)
accuracy= 0.31342105263157893
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158, 0.3101315789473684, 0.3240789473684211, 0.31342105263157893]
Running Loop: 9/10
Epoch 1, Loss: 1.3848
Epoch 2, Loss: 1.3823
Epoch 3, Loss: 1.3799
Epoch 4, Loss: 1.3776
Epoch 5, Loss: 1.3753
Epoch 6, Loss: 1.3730
Epoch 7, Loss: 1.3706
Epoch 8, Loss: 1.3682
Epoch 9, Loss: 1.3655
Epoch 10, Loss: 1.3627
Test set: Average loss: 0.0213, Accuracy: 2492/7600 (32.79%)
accuracy= 0.32789473684210524
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158, 0.3101315789473684, 0.3240789473684211, 0.31342105263157893, 0.32789473684210524]
Running Loop: 10/10
Epoch 1, Loss: 1.3859
Epoch 2, Loss: 1.3837
Epoch 3, Loss: 1.3819
Epoch 4, Loss: 1.3803
Epoch 5, Loss: 1.3788
Epoch 6, Loss: 1.3773
Epoch 7, Loss: 1.3759
Epoch 8, Loss: 1.3745
Epoch 9, Loss: 1.3732
Epoch 10, Loss: 1.3718
Test set: Average loss: 0.0215, Accuracy: 2319/7600 (30.51%)
accuracy= 0.3051315789473684
accuracies= [0.3126315789473684, 0.3161842105263158, 0.3207894736842105, 0.33, 0.3311842105263158, 0.3101315789473684, 0.3240789473684211, 0.31342105263157893, 0.32789473684210524, 0.3051315789473684]

Running AG News Training with Optimizer = SimpleSGDCurvature
params= {'lr': 0.001, 'epsilon': 0.01}
Running Loop: 1/10
Epoch 1, Loss: 1.2969
Epoch 2, Loss: 1.2409
Epoch 3, Loss: 1.4048
Epoch 4, Loss: 1.3532
Epoch 5, Loss: 1.3595
Epoch 6, Loss: 1.3506
Epoch 7, Loss: 1.3384
Epoch 8, Loss: 1.3290
Epoch 9, Loss: 1.3302
Epoch 10, Loss: 1.3089
Test set: Average loss: 0.0200, Accuracy: 3281/7600 (43.17%)
accuracy= 0.4317105263157895
accuracies= [0.4317105263157895]
Running Loop: 2/10
Epoch 1, Loss: 1.2950
Epoch 2, Loss: 1.3110
Epoch 3, Loss: 1.2728
Epoch 4, Loss: 1.3349
Epoch 5, Loss: 1.3245
Epoch 6, Loss: 1.3676
Epoch 7, Loss: 1.3488
Epoch 8, Loss: 1.3406
Epoch 9, Loss: 1.3535
Epoch 10, Loss: 1.3523
Test set: Average loss: 0.0221, Accuracy: 2029/7600 (26.70%)
accuracy= 0.2669736842105263
accuracies= [0.4317105263157895, 0.2669736842105263]
Running Loop: 3/10
Epoch 1, Loss: 1.2877
Epoch 2, Loss: 1.2807
Epoch 3, Loss: 1.3793
Epoch 4, Loss: 1.3632
Epoch 5, Loss: 1.3431
Epoch 6, Loss: 1.3240
Epoch 7, Loss: 1.3102
Epoch 8, Loss: 1.3203
Epoch 9, Loss: 1.3216
Epoch 10, Loss: 1.3029
Test set: Average loss: 0.0205, Accuracy: 3086/7600 (40.61%)
accuracy= 0.4060526315789474
accuracies= [0.4317105263157895, 0.2669736842105263, 0.4060526315789474]
Running Loop: 4/10
Epoch 1, Loss: 1.3889
Epoch 2, Loss: 1.3817
Epoch 3, Loss: 1.3620
Epoch 4, Loss: 1.3405
Epoch 5, Loss: 1.3244
Epoch 6, Loss: 1.3178
Epoch 7, Loss: 1.3103
Epoch 8, Loss: 1.3190
