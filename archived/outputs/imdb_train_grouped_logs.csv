Optimizer Name|Mean_Training_Loss_epoch1|Mean_Training_Loss_epoch2|Std_Training_Loss_epoch1|Std_Training_Loss_epoch2
AMSGrad|0.00953|0.00081|0.0011557104597028907|0.0007370361064576294
Adadelta|0.55723|0.34313|0.04232637869382798|0.024478518927600345
Adagrad|0.011519999999999999|0.00163|0.0012145415230082135|0.0003831158803518562
Adam|0.01014|0.00156|0.0019328735085359313|0.0029762765701833263
AdamW|0.01005|0.00040999999999999994|0.0014238055422782364|0.0004605552204797065
HeavyBall|0.093|0.00787|0.005280993172584954|0.0019373808207072873
HeavyBallCurvature|0.00583|2e-05|0.0002668749186833079|4.216370213557839e-05
NAG|0.093|0.00787|0.005280993172584954|0.0019373808207072873
NAGCurvature|0.00583|2e-05|0.0002668749186833079|4.216370213557839e-05
NAdam|0.01252|0.0083|0.012888823754624695|0.014685291205072434
NAdamW|0.01036|0.0052|0.006878016509947553|0.007020129786707809
RMSProp|0.00882|0.00126|0.009295255659624309|0.0016493769867572557
RMSPropMomentum|0.01004|0.00035999999999999997|0.009163841989034948|0.000340587727318528
SimpleSGD|0.30935999999999997|0.14667|0.01815557459539324|0.010055076108889262
SimpleSGDCurvature|0.01046|0.0001|0.0004788875998951463|0.0
